import streamlit as st
import google.generativeai as genai
import time

# --------------------------------------------------------------------------
# 1. ì„¤ì • ë° êµ¬ì„± (Configuration)
# --------------------------------------------------------------------------

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="Happy Delivery AI",
    page_icon="ğŸšš",
    layout="centered"
)

# [ë³´ì•ˆ ì£¼ì˜] ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” ì´ í‚¤ë¥¼ st.secretsì— ì €ì¥í•´ì„œ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.
# í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì§ì ‘ ì…ë ¥í•´ ë‘ì—ˆìŠµë‹ˆë‹¤.
API_KEY = "AIzaSyBVxYQzLTs8uRP4yyJYS8yBDewLSm896Jg"

# --------------------------------------------------------------------------
# [ì¤‘ìš”] AI Studioì˜ 'System Instructions' ë‚´ìš©ì„ ì•„ë˜ ë”°ì˜´í‘œ ì•ˆì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.
# ì˜ˆ: "ë„ˆëŠ” ì¹œì ˆí•œ ë°°ë‹¬ ìƒë‹´ì›ì´ì•¼. ê³ ê°ì˜ ì£¼ë¬¸ ìƒíƒœë¥¼ í™•ì¸í•´ì¤˜..."
# --------------------------------------------------------------------------
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ìµœê³ ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ë©°, ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ìƒë™ê° ìˆê²Œ ëŒ€í™”í•˜ì„¸ìš”.
(ì´ê³³ì— Google AI Studioì—ì„œ ì‘ì„±í–ˆë˜ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ë®ì–´ì“°ê¸° í•˜ì„¸ìš”)
"""

# ëª¨ë¸ ì„¤ì • (ê°€ì¥ ê°€ì„±ë¹„ ì¢‹ê³  ë¹ ë¥¸ ëª¨ë¸ ì„ íƒ)
MODEL_NAME = "gemini-1.5-flash" 

# --------------------------------------------------------------------------
# 2. ë¡œì§ êµ¬í˜„ (Backend Logic)
# --------------------------------------------------------------------------

def configure_genai():
    try:
        genai.configure(api_key=API_KEY)
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ëœ ëª¨ë¸ ìƒì„±
        model = genai.GenerativeModel(
            model_name=MODEL_NAME,
            system_instruction=SYSTEM_PROMPT
        )
        return model
    except Exception as e:
        st.error(f"API ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëª¨ë¸ ì´ˆê¸°í™”
model = configure_genai()

# --------------------------------------------------------------------------
# 3. í™”ë©´ êµ¬í˜„ (Frontend UI)
# --------------------------------------------------------------------------

st.title("ğŸšš Happy Delivery AI Service")
st.markdown("---")

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ì±„íŒ…ì°½ ìœ ì§€)
for message in st.session_state.messages:
    role = "user" if message["role"] == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # 2. ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 3. AI ì‘ë‹µ ìƒì„±
    if model:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # ë¬¸ë§¥(Context) ìœ ì§€ë¥¼ ìœ„í•´ ê³¼ê±° ëŒ€í™” ë‚´ìš©ì„ ëª¨ë¸ì— ì „ë‹¬
                # Gemini API í˜•ì‹ì— ë§ê²Œ ë³€í™˜
                history_for_api = []
                for msg in st.session_state.messages[:-1]: # í˜„ì¬ ì§ˆë¬¸ ì œì™¸í•˜ê³  ê³¼ê±° ê¸°ë¡ë§Œ
                    role = "user" if msg["role"] == "user" else "model"
                    history_for_api.append({"role": role, "parts": [msg["content"]]})
                
                chat = model.start_chat(history=history_for_api)
                response = chat.send_message(prompt, stream=True)
                
                # íƒ€ì ì¹˜ëŠ” íš¨ê³¼(Streaming) êµ¬í˜„
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                        
                message_placeholder.markdown(full_response)
                
                # 4. AI ì‘ë‹µ ê¸°ë¡ ì €ì¥
                st.session_state.messages.append({"role": "model", "content": full_response})
                
            except Exception as e:
                error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "model", "content": error_msg})

# ì‚¬ì´ë“œë°” (ì¶”ê°€ ê¸°ëŠ¥)
with st.sidebar:
    st.header("ì„¤ì •")
    if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™” ğŸ—‘ï¸"):
        st.session_state.messages = []
        st.rerun()
    st.caption(f"Model: {MODEL_NAME}")
    st.caption("Powered by Google Gemini")
