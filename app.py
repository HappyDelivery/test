import streamlit as st
import google.generativeai as genai
import os

# 1. í™”ë©´ ì„¤ì •
st.set_page_config(page_title="AI ì†”ë£¨ì…˜ ê°€ì´ë“œ", page_icon="ğŸ¤–")

st.title("ğŸ¤– AI ì†”ë£¨ì…˜ ê°€ì´ë“œ")

# [ë²„ì „ í™•ì¸ìš© ì½”ë“œ] í™”ë©´ì— í˜„ì¬ ë„êµ¬ ë²„ì „ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
# ë§Œì•½ ì´ ìˆ«ìê°€ 0.8.3ë³´ë‹¤ ë‚®ê²Œ ë‚˜ì˜¤ë©´ ì—…ë°ì´íŠ¸ê°€ ì•ˆ ëœ ê±°ì˜ˆìš”!
st.caption(f"ğŸ”§ í˜„ì¬ ë„êµ¬ ë²„ì „: {genai.__version__}") 

st.write("ë‹¹ì‹ ì—ê²Œ ë”± ë§ëŠ” AI ë„êµ¬ë¥¼ ì°¾ì•„ë“œë¦¬ê³ , í™œìš©ë²•ê¹Œì§€ ì•Œë ¤ë“œë ¤ìš”!")

# 2. ë¹„ë°€ ê¸ˆê³ ì—ì„œ ì—¬ê¶Œ(API Key) êº¼ë‚´ê¸°
my_api_key = os.environ.get("GOOGLE_API_KEY")

if not my_api_key:
    st.info("ì„¤ì •ì„ ìœ„í•´ ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”... (API Key ì¤€ë¹„ ì¤‘)")
    st.stop()

# 3. AI ë¡œë´‡ ì„¤ì •
genai.configure(api_key=my_api_key)

system_instruction = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ì¶° ìµœì ì˜ AI ë„êµ¬ë¥¼ ì¶”ì²œí•´ ì£¼ëŠ” 'AI í™œìš© ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ë‹¤ìŒ ìˆœì„œì™€ í˜•ì‹ì— ë§ì¶° ë‹µë³€í•´ì£¼ì„¸ìš”:
1. **ì¶”ì²œ AI ë„êµ¬:** (ê°€ì¥ ì í•©í•œ ë„êµ¬ ì´ë¦„)
2. **ê°€ê²© ì •ì±…:** (ë¬´ë£Œ / ìœ ë£Œ / ë¶€ë¶„ ìœ ë£Œ ë“± ëª…ì‹œ)
3. **í™œìš© ë°©ë²• (Step-by-Step):** ì´ˆë³´ìë„ ë”°ë¼ í•  ìˆ˜ ìˆê²Œ 1, 2, 3 ë‹¨ê³„ë¡œ ì•„ì£¼ ì‰½ê²Œ ì„¤ëª…
4. **í™œìš© ì˜ˆì‹œ:** ì‹¤ì œ ì ìš©í•´ ë³¼ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì‚¬ë¡€
**ì£¼ì˜ì‚¬í•­:** ì„¤ëª…ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.
"""

# ë‹¤ì‹œ ìµœì‹  ëª¨ë¸(gemini-1.5-flash)ë¡œ ë³€ê²½!
model = genai.GenerativeModel(
    'gemini-1.5-flash',
    system_instruction=system_instruction
)

# 4. ì±„íŒ…ì°½ ë§Œë“¤ê¸°
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ì–´ë–¤ AIê°€ í•„ìš”í•˜ì‹ ê°€ìš”? (ì˜ˆ: ë¡œê³ ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ë¬´ë£Œ AI ì¶”ì²œí•´ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ì „ë¬¸ê°€ê°€ ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                response = model.generate_content(prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"ì—ëŸ¬ê°€ ë‚¬ì–´ìš”: {e}")
